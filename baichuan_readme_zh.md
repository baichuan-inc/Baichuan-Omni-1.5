**支持文本、图像、视频、音频输入以及高质量文本、音频输出的多模态大模型**


**Baichuan-omni-1.5** 是从 Baichuan-omni 升级的最新的端到端训练的支持全模态输入，双模态输出的多模态大模型。该模型使用了7B的LLLM，可以以端到端方式，接受图像、视频、文本、音频作为输入，并生成高质量文本和语音输出。自2024年10月以来，我们以实现高性能和端到端的兼容多个模态为目标，发布了3个版本的模型。目前系列中最值得关注的模型包括：

- **Baichuan-omni**: Baichuan-omni 是**业内首个**(2024.10)开源的能够处理文本、音频、图像、视频的全模态模型。该模型基于 SigLip-400M、Whisper-medium-300M、ChatTTS-200M 和 Qwen2.5-7B 构建，共 xxxB 参数，使用高质量的全模态数据，通过端到端方式训练和推理。

- **Baichuan-omni-1.5 base**: 为促进全模态大模型发展，我们开源了使用海量数据训练的全模态基座模型，该模型未经SFT指令微调，可塑性强。Baichuan-omni-1.5 base 是**业内首个**开源的全模态纯基座模型。

- **Baichuan-omni-1.5 instruct**: 基于性能强悍的Baichuan-omni-1.5 base，使用高质量的全模态对齐数据，进行端到端的多模态指令数据训练。Baichuan-omni-1.5 总参数量 xxx B，**视觉、语音和多模态流式能力达到了 GPT-4o-mini 级别**，是开源社区中模态支持最丰富、性能一流的模型之一。在新的语音模式中，Baichuan-omni-1.5 **支持高质量可控制声音的中英双语语音对话，还具备情感/语速/风格控制、端到端声音克隆、角色扮演等进阶能力**。模型也进一步提升了 Baichuan-omni-1.5 的 **OCR、医疗图像理解、和视频理解等视觉能力**。基于其领先的高质量数据、端到端的全模态训练策略，Baichuan-omni-1.5 成为了**首个在各个模态上都具有一流表现**的多模态大模型。

## Baichuan-omni-1.5

Baichuan-omni-1.5 是 Baichuan-omni 系列的最新、性能一流模型。该模型基于 NaVit-xxxM、Whisper-medium-300M、ChatTTS-200M 和 Qwen2.5-7B 构建，共 xxxB 参数，通过端到端方式训练和推理。相比 Baichuan-omni，该模型在性能上有了显著提升，并支持了实时语音对话和多模态流式交互的新功能。Baichuan-omni-1.5 的主要特性包括：

- **强大的多模态理解和交互能力。**
Baichuan-omni-1.5 接受图像、视频、文本、音频作为输入，并生成高质量文本和语音输出，能够**接受连续的视频和音频流，并和用户进行实时语音交互**。在针对全模态理解的综合评测基准 OminiBench 中，Baichuan-omni-1.5 取得开源社区一流水平，并**超过了 GPT-4o-mini 和 MiniCPM-o 2.6**。

- **领先的视觉能力。**
Baichuan-omni-1.5 在 OpenCompass 榜单上（综合 xxx 个主流多模态评测基准）平均得分 xxx，**以 8B 量级的大小在单图理解方面超越了 GPT-4o-mini、Gemini 1.5 Pro 和 Claude 3.5 Sonnet 等主流商用闭源多模态大模型**。此外，它的视频理解表现也**优于 GPT-4V 和 Claude 3.5 Sonnet**，并展现出了优秀的上下文学习能力。

- **极好的医疗图像理解能力。**
Baichuan-omni-1.5 在GMAI-MMBench以及Openmm-Medical上取得了最佳的表现。均分上，超过Qwen2-VL-72b 3分，即 80.01 v.s 83.3.

- **出色的语音能力。**
Baichuan-omni-1.5 **支持高质量可控制声音的中英双语实时对话**。Baichuan-omni-1.5 在语音理解任务（如 ASR 和 STT 等）**优于 GPT-4o-realtime**，并在语音对话的语义和声学评估中展现了**开源模型中最高的语音生成性能**。它还支持情绪/语速/风格控制、语音克隆、角色扮演等进阶能力。

- **强大的 OCR 能力及其他功能。**
Baichuan-omni-1.5 进一步优化了 Baichuan-omni 的众多视觉理解能力，其可以处理任意长宽比的图像，像素数可达 180 万（如 1344x1344）。在 OCRBench 上取得**25B 以下一流水平，超过 GPT-4o-mini 等商用闭源模型**。


**模型架构。**

- **端到端全模态架构。** 通过**端到端**的方式连接和训练不同模态的编/解码模块以充分利用丰富的多模态知识。全模态阶段，模型完全使用 NTP 损失进行端到端训练。
- **高质量可控制的声音方案。** 我们设计了新的多模态系统提示，包含传统文本系统提示词，和**用于指定模型声音的语音系统提示词**。模型可在推理时灵活地通过文字或语音样例控制声音风格，并支持端到端声音克隆和音色创建等高级能力。


### 性能评估


**图像理解能力**